{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_simple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYw9oznTGhVx"
      },
      "source": [
        "Základní CNN s rozpoznáváním psaných číslic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQgXQ7HMZnnu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxLo2ee51FmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784a7302-6d1b-46ee-f67d-e78d56f5c10b"
      },
      "source": [
        "import os\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip'\n",
        "!wget -qq 'https://github.com/lukyfox/Datafiles/raw/master/digits/digits.zip'  \n",
        "!unzip -qq '/content/digits.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/it4n_train_reduced.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ_augmented.zip'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace digits/validation/1/img_41119.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_jDvfuulS8T"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras import backend\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class AccuracyCallback(Callback):\n",
        "    def __init__(self, test_data, classes):\n",
        "        self.test_data = test_data\n",
        "        self.classes = list(classes)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_data, y_data = self.test_data\n",
        "\n",
        "        correct = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        x_result = self.model.predict(x_data, verbose=0)\n",
        "\n",
        "        class_correct = [0] * len(self.classes)\n",
        "        class_incorrect = [0] * len(self.classes)\n",
        "\n",
        "        for i in range(len(x_data)):\n",
        "            x = x_data[i]\n",
        "            y = y_data[i]\n",
        "\n",
        "            res = x_result[i]\n",
        "\n",
        "            actual_label = np.argmax(y)\n",
        "            #print('actual_label =',actual_label)\n",
        "            pred_label = np.argmax(res)\n",
        "            #print('pred_label =', pred_label)\n",
        "\n",
        "            if(pred_label == actual_label):\n",
        "                class_correct[actual_label] += 1   \n",
        "                correct += 1\n",
        "            else:\n",
        "                class_incorrect[actual_label] += 1\n",
        "                incorrect += 1\n",
        "        print('\\tclass_correct =', class_correct)\n",
        "        print('\\tclass_incorrect =', class_incorrect)\n",
        "        print(\"\\tCorrect: %d\" %(correct))\n",
        "        print(\"\\tIncorrect: %d\" %(incorrect))\n",
        "\n",
        "        for i in range(len(self.classes)):\n",
        "            tot = float(class_correct[i] + class_incorrect[i])\n",
        "            print(f'tot({tot}) = float(class_correct[i]({class_correct[i]}) + class_incorrect[i]({class_incorrect[i]}))')\n",
        "            class_acc = -1\n",
        "            if (tot > 0):\n",
        "                class_acc = float(class_correct[i]) / tot\n",
        "                print(f'class_acc({class_acc}) = float(class_correct[i])({class_correct[i]}) / tot({tot})')\n",
        "\n",
        "            print(\"\\tself.classes[i] = %s: class_acc = %.3f\" %(self.classes[i],class_acc)) \n",
        "\n",
        "        acc = float(correct) / float(correct + incorrect)  \n",
        "        print(f'acc({acc}) = float(correct)({correct}) / float(correct + incorrect)({correct+incorrect})')\n",
        "\n",
        "        print(\"\\tCurrent Network Accuracy: %.3f\" %(acc))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlw1Qg7gPPVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dc3a40-c925-44b2-fbea-6c1bec368be8"
      },
      "source": [
        "# import relevant functions\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "# rotate, and shift data\n",
        "#image_gen = ImageDataGenerator(rotation_range=20,\n",
        "#                              width_shift_range=0.1,\n",
        "#                              height_shift_range=0.1,\n",
        "#                              shear_range=0.1,\n",
        "#                              zoom_range=0.1,\n",
        "#                              horizontal_flip=True,\n",
        "#                              fill_mode='nearest')\n",
        "\n",
        "image_gen = ImageDataGenerator(rescale=1.0/255)\n",
        "# build the model\n",
        "\n",
        "#image_shape = (330, 330, 3)\n",
        "image_shape = (32, 32, 3)\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "learn_rate=0.001\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# set up early stopping - overfitting solution + speed up processing\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "# build train and test generators\n",
        "#train_path = '/content/_splitted/train'\n",
        "train_path = '/content/digits/train'\n",
        "#train_path = '/content/cwe3categ_augmented/train'\n",
        "train_image_gen = image_gen.flow_from_directory(train_path,\n",
        "                                               target_size = image_shape[:2],\n",
        "                                               color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "# don't shuffle test data\n",
        "#test_path = '/content/_splitted/validation'\n",
        "test_path = '/content/digits/validation'\n",
        "#test_path = '/content/cwe3categ_augmented/validation'\n",
        "\n",
        "test_image_gen = image_gen.flow_from_directory(test_path,\n",
        "                                               target_size = image_shape[:2],\n",
        "                                               color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=False)\n",
        "\n",
        "accuracy_callback = AccuracyCallback(test_image_gen, [0,1,2])\n",
        "\n",
        "# fit on the generators\n",
        "results = model.fit(train_image_gen, epochs=20,\n",
        "                             validation_data=test_image_gen,\n",
        "                             #callbacks=[early_stopping, accuracy_callback]\n",
        "                    )\n",
        "results.history"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9880 images belonging to 3 classes.\n",
            "Found 3113 images belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "618/618 [==============================] - 25s 13ms/step - loss: 0.0770 - accuracy: 0.9720 - val_loss: 0.0325 - val_accuracy: 0.9900\n",
            "Epoch 2/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
            "Epoch 3/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0110 - val_accuracy: 0.9981\n",
            "Epoch 4/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
            "Epoch 5/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0093 - val_accuracy: 0.9965\n",
            "Epoch 6/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 7/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
            "Epoch 8/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9978\n",
            "Epoch 9/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
            "Epoch 10/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0110 - val_accuracy: 0.9968\n",
            "Epoch 11/20\n",
            "618/618 [==============================] - 8s 12ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0058 - val_accuracy: 0.9971\n",
            "Epoch 12/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
            "Epoch 13/20\n",
            "618/618 [==============================] - 7s 11ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0377 - val_accuracy: 0.9945\n",
            "Epoch 14/20\n",
            "618/618 [==============================] - 8s 12ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0074 - val_accuracy: 0.9978\n",
            "Epoch 15/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
            "Epoch 16/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 5.9934e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9978\n",
            "Epoch 17/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
            "Epoch 18/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0096 - val_accuracy: 0.9978\n",
            "Epoch 19/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0147 - val_accuracy: 0.9978\n",
            "Epoch 20/20\n",
            "618/618 [==============================] - 7s 12ms/step - loss: 6.9198e-04 - accuracy: 0.9998 - val_loss: 0.0257 - val_accuracy: 0.9971\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.9719635844230652,\n",
              "  0.992813766002655,\n",
              "  0.9959514141082764,\n",
              "  0.9962550401687622,\n",
              "  0.9964575171470642,\n",
              "  0.9988866448402405,\n",
              "  0.9979757070541382,\n",
              "  0.9976720809936523,\n",
              "  0.9987854361534119,\n",
              "  0.9997975826263428,\n",
              "  0.9963562488555908,\n",
              "  0.9985830187797546,\n",
              "  0.9991902709007263,\n",
              "  0.9987854361534119,\n",
              "  0.9993926882743835,\n",
              "  1.0,\n",
              "  0.9987854361534119,\n",
              "  0.9994939565658569,\n",
              "  0.9990890622138977,\n",
              "  0.9997975826263428],\n",
              " 'loss': [0.0769883543252945,\n",
              "  0.021585850045084953,\n",
              "  0.01351700909435749,\n",
              "  0.011718499474227428,\n",
              "  0.010437392629683018,\n",
              "  0.003656608983874321,\n",
              "  0.005942370742559433,\n",
              "  0.007743736729025841,\n",
              "  0.0037473735865205526,\n",
              "  0.0013580884551629424,\n",
              "  0.012825550511479378,\n",
              "  0.0034016799181699753,\n",
              "  0.002439531497657299,\n",
              "  0.0033627671655267477,\n",
              "  0.0028568259440362453,\n",
              "  5.993447848595679e-05,\n",
              "  0.005846542306244373,\n",
              "  0.003347464371472597,\n",
              "  0.0043944926001131535,\n",
              "  0.0006919779116287827],\n",
              " 'val_accuracy': [0.9900417327880859,\n",
              "  0.9945390224456787,\n",
              "  0.998072624206543,\n",
              "  0.998072624206543,\n",
              "  0.9964664578437805,\n",
              "  0.9990363121032715,\n",
              "  0.998072624206543,\n",
              "  0.9977513551712036,\n",
              "  0.998072624206543,\n",
              "  0.9967876672744751,\n",
              "  0.9971088767051697,\n",
              "  0.9961451888084412,\n",
              "  0.9945390224456787,\n",
              "  0.9977513551712036,\n",
              "  0.9971088767051697,\n",
              "  0.9977513551712036,\n",
              "  0.998072624206543,\n",
              "  0.9977513551712036,\n",
              "  0.9977513551712036,\n",
              "  0.9971088767051697],\n",
              " 'val_loss': [0.03248338773846626,\n",
              "  0.017721544951200485,\n",
              "  0.010955184698104858,\n",
              "  0.00528847798705101,\n",
              "  0.009341268800199032,\n",
              "  0.004722145386040211,\n",
              "  0.006088389083743095,\n",
              "  0.005272183567285538,\n",
              "  0.005294262431561947,\n",
              "  0.010983040556311607,\n",
              "  0.005776538047939539,\n",
              "  0.011920473538339138,\n",
              "  0.037723805755376816,\n",
              "  0.007448866497725248,\n",
              "  0.009807498194277287,\n",
              "  0.009072426706552505,\n",
              "  0.010724659077823162,\n",
              "  0.009586199186742306,\n",
              "  0.014704625122249126,\n",
              "  0.025721782818436623]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52pvR1ftZwbX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}