{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_VGG16_KapEnd_FE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhGbjgYYGZ9l"
      },
      "source": [
        "VGG16 s feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPoGW4b5BMG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8336a647-e66f-4a4b-f311-6a5f6f540518"
      },
      "source": [
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/digits/digits_small.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ_augmented.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/it4n_train_reduced.zip'\n",
        "\n",
        "# TESTOVACI DATA \n",
        "# (CWE pics jsou navic tak trochu protected mimo svatou pudu alma mater)\n",
        "!wget -qq 'https://github.com/lukyfox/Datafiles/raw/master/digits/digits.zip'  \n",
        "!unzip -qq '/content/digits.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip, /content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip.zip or /content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyQhwRs64EaF"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras import backend\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class AccuracyCallback(Callback):\n",
        "    def __init__(self, test_data, classes):\n",
        "        self.test_data = test_data\n",
        "        self.classes = list(classes)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_data, y_data = self.test_data\n",
        "\n",
        "        correct = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        x_result = self.model.predict(x_data, verbose=0)\n",
        "\n",
        "        class_correct = [0] * len(self.classes)\n",
        "        class_incorrect = [0] * len(self.classes)\n",
        "\n",
        "        for i in range(len(x_data)):\n",
        "            x = x_data[i]\n",
        "            y = y_data[i]\n",
        "\n",
        "            res = x_result[i]\n",
        "\n",
        "            actual_label = np.argmax(y)\n",
        "            #print('actual_label =',actual_label)\n",
        "            pred_label = np.argmax(res)\n",
        "            #print('pred_label =', pred_label)\n",
        "\n",
        "            if(pred_label == actual_label):\n",
        "                class_correct[actual_label] += 1   \n",
        "                correct += 1\n",
        "            else:\n",
        "                class_incorrect[actual_label] += 1\n",
        "                incorrect += 1\n",
        "        print('\\tclass_correct =', class_correct)\n",
        "        print('\\tclass_incorrect =', class_incorrect)\n",
        "        print(\"\\tCorrect: %d\" %(correct))\n",
        "        print(\"\\tIncorrect: %d\" %(incorrect))\n",
        "\n",
        "        for i in range(len(self.classes)):\n",
        "            tot = float(class_correct[i] + class_incorrect[i])\n",
        "            print(f'tot({tot}) = float(class_correct[i]({class_correct[i]}) + class_incorrect[i]({class_incorrect[i]}))')\n",
        "            class_acc = -1\n",
        "            if (tot > 0):\n",
        "                class_acc = float(class_correct[i]) / tot\n",
        "                print(f'class_acc({class_acc}) = float(class_correct[i])({class_correct[i]}) / tot({tot})')\n",
        "\n",
        "            print(\"\\tself.classes[i] = %s: class_acc = %.3f\" %(self.classes[i],class_acc)) \n",
        "\n",
        "        acc = float(correct) / float(correct + incorrect)  \n",
        "        print(f'acc({acc}) = float(correct)({correct}) / float(correct + incorrect)({correct+incorrect})')\n",
        "\n",
        "        print(\"\\tCurrent Network Accuracy: %.3f\" %(acc))\n",
        "\n",
        "\n",
        "\n",
        "# reset all states, mozna to k nicemu neni, ale pro ten pocit...\n",
        "backend.clear_session()\n",
        "\n",
        "image_shape = (330, 330, 3)\n",
        "# VGG16 ma minimalni pozadavky na image shape (32, 32, 3), pro test \"mnist\"\n",
        "# (10k pics trenovacich cislic 0-2, 3k validacnich, dim 28x28 v 1 gs kanalu) tedy musim \n",
        "# tak jako tak volit minimalni shape vstupu dle VGG16. Se stejnym nastavenim site \n",
        "# se s mnist dostavam k presnosti pres 99% a overfittingu pod 1%. Testovanim \n",
        "# mnist sady (o vysokem kontrastu) zjistuju, jestli model vubec funguje (a on asi fakt funguje),\n",
        "# navic uz je i tady patrny posun v presnosti oproti CNN simple.\n",
        "# Presnost pro kapslovku je 75-80%, prakticky stejna jako u CNN simple.\n",
        "image_shape = (32, 32, 3)\n",
        "\n",
        "# conv_base je konvolucni baze z VGG19, include_top=False rika, ze do conv_base nenacitam klasifikator, \n",
        "# ale pripojim si vlastni - duvodem je, ze trenuju nad daty, ktera nejsou z ImageNet (je tam 1000 trid, \n",
        "# ale strev se asi netyka ani jedna), muj klasifikator se tak musi naucit nove vzory ale kvuli nizkemu poctu dat \n",
        "# je stale dobre vyuzit obecne features z konvolucnich vrstev VGG19\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
        "for layer in conv_base.layers[:]:\n",
        "  layer.trainable = False\n",
        "# vypis vrstev modelu\n",
        "conv_base.summary()\n",
        "\n",
        "# 2. nacteni dat a jejich prepocet dle konvoluce z VGG16\n",
        "# ImageDataGenerator uz mi staci jen jeden, protoze nemusi mit augmentaci. Duvodem je,\n",
        "# ze pouzivam jiz naucene features z konvolucni casti VGG16 a tudiz nemam kde\n",
        "# uplatnit svou pripadnou augmentaci (transformace mi k nicemu nejsou, ve vahach\n",
        "# z VGG16 jsou jiz uplatneny transformace z uceni na ImageNetu)\n",
        "imagedatagen = ImageDataGenerator()\n",
        "batch_size = 20\n",
        "\n",
        "# funkce pro extrakci features z vlastni datove sady protazene pres VGG16, prvni\n",
        "# beh trva dlouho, zejmena pro vetsi datovou sadu, ale pak se asi nakesuje a je\n",
        "# to celkem ficak... (je to funkce, protoze stejny kod pouzivam 2x)\n",
        "def extract_features_from_conv_layers(source_dir):\n",
        "  # vytahnu si data z adresaru do kategorizovaneho toku\n",
        "  imageflow = imagedatagen.flow_from_directory(\n",
        "      source_dir, \n",
        "      # color mode rgb nechavam u VGG16 i pro mnist\n",
        "      color_mode= 'rgb', \n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      target_size = image_shape[:2])\n",
        "  \n",
        "  counter = Counter(imageflow.classes)\n",
        "  print(counter.items())\n",
        "  class_dict = imageflow.class_indices\n",
        "  # zjistim pocet samplu v source_dir\n",
        "  sample_count = imageflow.samples\n",
        "  # vytvorim nulovy tenzor o rozmerech (sample_count, 10, 10, 512) - 3 posledni \n",
        "  # cisla vychazeji ze shapu vystupni konvolucni VGG16 vrstvy (info ze summary) \n",
        "  features = np.zeros(shape=(sample_count, 10, 10, 512))\n",
        "  # udelam to same pro labely, ty jsou vlastne jen numpy polem\n",
        "  labels = np.zeros(shape=(sample_count,len(class_dict.keys())))\n",
        "  # a v cyklu plnim features a labels prepocitanymi features z konvolucni baze,\n",
        "  # nove features (a nezmenene labels) jsou vstupem do vlastniho klasifikatoru  \n",
        "  i = 0\n",
        "  for input_batch, label_batch in imageflow:\n",
        "    # predict vraci vystupni parametry po konvoluci\n",
        "    # https://www.youtube.com/watch?v=ZJRPTBVBV5c&feature=youtu.be&t=1407\n",
        "    features[i*batch_size : (i+1)*batch_size] = conv_base.predict(input_batch)\n",
        "    labels[i*batch_size : (i+1)*batch_size] = label_batch\n",
        "    i += 1\n",
        "    # iterace v generatoru bezi do nekonecna (jestli tomu spravne rozumim, \n",
        "    # flow_from_directory prohledava cilove adresare v nekonecne smycce), proto\n",
        "    # musim beh ukoncit, jakmile zpracuju posledni sample\n",
        "    #print('samples processed:', i*batch_size, 'of', sample_count, 'label_batch =', label_batch)\n",
        "    if i*batch_size >= sample_count:\n",
        "      print('sample processing finished: i*batch_size >= sample_count =', i*batch_size, '>=', sample_count)\n",
        "      break\n",
        "\n",
        "  return features, labels, sample_count, counter\n",
        "\n",
        "# prepocitam sample pictures ze vstupnich slozek podle konvolucnich vrstev VGG16 \n",
        "# a vratim pro vstup do vlastniho klasifikatoru (train_features tedy obsahuje \n",
        "# features z kapslovky transformovane dle VGG19 naucene z ImageNetu)\n",
        "#train_path = '/content/_splitted/train'\n",
        "train_path = '/content/digits/train'\n",
        "#train_path = '/content/cwe3categ_augmented/train'\n",
        "#train_path = '/content/it4n_balanced'\n",
        "#train_path = '/content/drive/MyDrive/Datafiles/cwe_dataset/train'\n",
        "#train_path = '/content/drive/MyDrive/Datafiles/it4n_2categs/train'\n",
        "\n",
        "train_features, train_labels, sample_count, classes = extract_features_from_conv_layers(train_path)\n",
        "# reshapnu vystup, aby odpovidal ocekavanemu vstupu do klasifikatoru (obdoba Flatten vrstvy),\n",
        "# 10*10*512 naopak odpovida vystupu z posledni konvolucni vrstvy VGG16\n",
        "print('sample_count:', sample_count)\n",
        "print(train_features.shape)\n",
        "train_features = np.reshape(train_features, (sample_count, 10*10*512))\n",
        "print(train_features.shape)\n",
        "\n",
        "#validation_path = '/content/_splitted/validation'\n",
        "validation_path = '/content/digits/validation'\n",
        "#validation_path = '/content/cwe3categ_augmented/validation'\n",
        "#validation_path = '/content/drive/MyDrive/Datafiles/cwe_dataset/validation'\n",
        "#validation_path = '/content/drive/MyDrive/Datafiles/it4n_2categs/validation'\n",
        "val_features, val_labels, sample_count, classes = extract_features_from_conv_layers(validation_path)\n",
        "print(val_features.shape)\n",
        "val_features = np.reshape(val_features, (sample_count, 10*10*512))\n",
        "print(val_features.shape)\n",
        "\n",
        "# 3. definice vlastniho klasifikatoru k napojeni na vystupni features z VGG16,\n",
        "# jedna se vlastne o stejny klasifikator, jaky jsem pouzil u simple CNN\n",
        "model = Sequential()\n",
        "# vstupni vrstva ma input_dim = 10*10*512 = 51200, coz odpovida features po reshapingu (Dense vyzaduje 1D tenzor na vstupu),\n",
        "# bez reshapu vyse by se musela jako prvni vrstva klasifikatoru dat Flatten\n",
        "model.add(Dense(256, activation='relu', input_dim=51200))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(classes.keys()), activation='softmax'))\n",
        "\n",
        "# 4. sestaveni modelu a spusteni trenovani\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
        "accuracy_callback = AccuracyCallback((val_features, val_labels), classes.keys())\n",
        "\n",
        "class_weight = {0: 100.0, 1: 1.0, 2: 1000.0}\n",
        "class_weight = {0: 1.0, 1: 1.0, 2: 1.0}\n",
        "\n",
        "epochs = 20\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=epochs,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=[early_stopping, accuracy_callback],\n",
        "    class_weight=class_weight\n",
        "    )\n",
        "\n",
        "# 5. vypis vysledku a vizualizace\n",
        "\n",
        "#print(classification_report(val_features, val_labels))\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "xepochs = range(1, len(accuracy)+1)\n",
        "\n",
        "plt.plot(xepochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(xepochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(xepochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(xepochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.figure()\n",
        "\n",
        "df = pd.DataFrame(history.history)\n",
        "print(df)\n",
        "\n",
        "#for data, label in validation_imageflow:\n",
        "#  print('data batch shape:', data.shape)\n",
        "#  plt.imshow(data[0])\n",
        "#  plt.title(str(label[0]))\n",
        "#  print('label batch shape:', label.shape)\n",
        "#  break\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXuRVqzuco_m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}