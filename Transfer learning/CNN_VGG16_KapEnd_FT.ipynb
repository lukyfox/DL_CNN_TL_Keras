{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_VGG16_KapEnd_FT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqzI3p-_GpCx"
      },
      "source": [
        "VGG16 s fine tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPoGW4b5BMG4"
      },
      "source": [
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/cwe3categ_augmented.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/it4n/it4n_train_reduced.zip'\n",
        "#!unzip -qq '/content/drive/MyDrive/Datafiles/digits/digits_small.zip'\n",
        "\n",
        "# TESTOVACI DATA\n",
        "!wget -qq 'https://github.com/lukyfox/Datafiles/raw/master/digits/digits.zip'  \n",
        "!unzip -qq '/content/digits.zip'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyQhwRs64EaF",
        "outputId": "f9387abb-b5b7-4c83-e197-91a19e295cbe"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras import backend, Input, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class AccuracyCallback(Callback):\n",
        "    def __init__(self, test_data, classes):\n",
        "        self.test_data = test_data\n",
        "        self.classes = list(classes)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        #batch_index = 0\n",
        "        #data_list = []\n",
        "        #while batch_index <= self.test_data.batch_index:\n",
        "        #  data = self.test_data.next()\n",
        "        #  data_list.append(data[0])\n",
        "        #  batch_index += 1\n",
        "\n",
        "        # now, data_array is the numeric data of whole images\n",
        "        #x_data = np.asarray(data_list)\n",
        "        #y_data = self.test_data.classes\n",
        "\n",
        "        x_data, y_data = self.test_data\n",
        "        correct = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        x_result = self.model.predict(x_data, verbose=0)\n",
        "\n",
        "        class_correct = [0] * len(self.classes)\n",
        "        class_incorrect = [0] * len(self.classes)\n",
        "\n",
        "        for i in range(len(x_data)):\n",
        "            x = x_data[i]\n",
        "            y = y_data[i]\n",
        "\n",
        "            res = x_result[i]\n",
        "\n",
        "            actual_label = np.argmax(y)\n",
        "            #print('actual_label =',actual_label)\n",
        "            pred_label = np.argmax(res)\n",
        "            #print('pred_label =', pred_label)\n",
        "\n",
        "            if(pred_label == actual_label):\n",
        "                class_correct[actual_label] += 1   \n",
        "                correct += 1\n",
        "            else:\n",
        "                class_incorrect[actual_label] += 1\n",
        "                incorrect += 1\n",
        "        print('\\tclass_correct =', class_correct)\n",
        "        print('\\tclass_incorrect =', class_incorrect)\n",
        "        print(\"\\tCorrect: %d\" %(correct))\n",
        "        print(\"\\tIncorrect: %d\" %(incorrect))\n",
        "\n",
        "        for i in range(len(self.classes)):\n",
        "            tot = float(class_correct[i] + class_incorrect[i])\n",
        "            print(f'tot({tot}) = float(class_correct[i]({class_correct[i]}) + class_incorrect[i]({class_incorrect[i]}))')\n",
        "            class_acc = -1\n",
        "            if (tot > 0):\n",
        "                class_acc = float(class_correct[i]) / tot\n",
        "                print(f'class_acc({class_acc}) = float(class_correct[i])({class_correct[i]}) / tot({tot})')\n",
        "\n",
        "            print(\"\\tself.classes[i] = %s: class_acc = %.3f\" %(self.classes[i],class_acc)) \n",
        "\n",
        "        acc = float(correct) / float(correct + incorrect)  \n",
        "        print(f'acc({acc}) = float(correct)({correct}) / float(correct + incorrect)({correct+incorrect})')\n",
        "\n",
        "        print(\"\\tCurrent Network Accuracy: %.3f\" %(acc))\n",
        "\n",
        "'''\n",
        "def extract_features_from_conv_layers(image_flow, conv_base):\n",
        "  # vytahnu si data z adresaru do kategorizovaneho toku\n",
        "  #counter = Counter(imageflow.classes)\n",
        "  #print(counter.items())\n",
        "  #class_dict = imageflow.class_indices\n",
        "  # zjistim pocet samplu v source_dir\n",
        "  sample_count = imageflow.samples\n",
        "  # vytvorim nulovy tenzor o rozmerech (sample_count, 10, 10, 512) - 3 posledni \n",
        "  # cisla vychazeji ze shapu vystupni konvolucni VGG16 vrstvy (info ze summary) \n",
        "  features = np.zeros(shape=(sample_count, 10, 10, 512))\n",
        "  # udelam to same pro labely, ty jsou vlastne jen numpy polem\n",
        "  labels = np.zeros(shape=(sample_count,len(class_dict.keys())))\n",
        "  # a v cyklu plnim features a labels prepocitanymi features z konvolucni baze,\n",
        "  # nove features (a nezmenene labels) jsou vstupem do vlastniho klasifikatoru  \n",
        "  i = 0\n",
        "  for input_batch, label_batch in imageflow:\n",
        "    features[i*batch_size : (i+1)*batch_size] = conv_base.predict(input_batch)\n",
        "    labels[i*batch_size : (i+1)*batch_size] = label_batch\n",
        "    i += 1\n",
        "    # iterace v generatoru bezi do nekonecna (jestli tomu spravne rozumim, \n",
        "    # flow_from_directory prohledava cilove adresare v nekonecne smycce), proto\n",
        "    # musim beh ukoncit, jakmile zpracuju posledni sample\n",
        "    #print('samples processed:', i*batch_size, 'of', sample_count, 'label_batch =', label_batch)\n",
        "    if i*batch_size >= sample_count:\n",
        "      break\n",
        "\n",
        "  return features, labels\n",
        "'''\n",
        "\n",
        "\n",
        "# reset all states, mozna to k nicemu neni, ale pro ten pocit...\n",
        "backend.clear_session()\n",
        "batch_size = 20\n",
        "epochs = 20\n",
        "image_shape = (330, 330, 3)\n",
        "#image_shape = (32, 32, 3)\n",
        "\n",
        "#train_path = '/content/_splitted/train'\n",
        "train_path = '/content/digits/train'\n",
        "#train_path = '/content/cwe3categ_augmented/train'\n",
        "#train_path = '/content/it4n_balanced'\n",
        "#train_path = '/content/drive/MyDrive/Datafiles/cwe_dataset/train'\n",
        "#train_path = '/content/drive/MyDrive/Datafiles/it4n_2categs/train'\n",
        "\n",
        "#validation_path = '/content/_splitted/validation'\n",
        "validation_path = '/content/digits/validation'\n",
        "#validation_path = '/content/cwe3categ_augmented/validation'\n",
        "#validation_path = '/content/drive/MyDrive/Datafiles/cwe_dataset/validation'\n",
        "#validation_path = '/content/drive/MyDrive/Datafiles/it4n_2categs/validation'\n",
        "\n",
        "conv_base = VGG16(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    #input_shape=image_shape\n",
        "    input_tensor=Input(shape=image_shape))\n",
        "\n",
        "\n",
        "# 1. nacteni dat a jejich prepocet dle konvoluce z VGG16\n",
        "# ImageDataGenerator musim mit pro train i validation kvuli augmentaci.\n",
        "train_imagedatagen = ImageDataGenerator(#rescale=1./255, \n",
        "                                  rotation_range=30,\n",
        "                                  zoom_range=0.1,\n",
        "                                  horizontal_flip=True,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  fill_mode='nearest')\n",
        "# pro validaci nejsou nahodne transformace potreba\n",
        "validation_imagedatagen = ImageDataGenerator()\n",
        "# nastavim prumerne hodnoty (z ImageNet) pro preprocessing - pricteni k pixelum obrazku,\n",
        "# opet pouze pro FT, u EF by to nebylo k nicemu \n",
        "train_imagedatagen.mean = np.array([123.68, 116.779, 103.939], dtype='float32')\n",
        "validation_imagedatagen.mean = np.array([123.68, 116.779, 103.939], dtype='float32')\n",
        "\n",
        "train_imageflow = train_imagedatagen.flow_from_directory(\n",
        "      train_path, \n",
        "      # color mode rgb nechavam u VGG16 i pro mnist\n",
        "      color_mode= 'rgb', \n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      target_size = image_shape[:2])\n",
        "  \n",
        "train_counter = Counter(train_imageflow.classes)\n",
        "print(train_counter.items())\n",
        "train_class_dict = train_imageflow.class_indices\n",
        "train_sample_count = train_imageflow.samples\n",
        "\n",
        "validation_imageflow = validation_imagedatagen.flow_from_directory(\n",
        "      validation_path, \n",
        "      # color mode rgb nechavam u VGG16 i pro mnist\n",
        "      color_mode= 'rgb', \n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      target_size = image_shape[:2])\n",
        "  \n",
        "validation_counter = Counter(validation_imageflow.classes)\n",
        "print(validation_counter.items())\n",
        "validation_class_dict = validation_imageflow.class_indices\n",
        "validation_sample_count = validation_imageflow.samples\n",
        "\n",
        "head_model = conv_base.output\n",
        "head_model = Flatten(name='flatten')(head_model)\n",
        "head_model = Dense(256, activation='relu')(head_model)\n",
        "head_model = Dropout(0.5)(head_model)\n",
        "head_model = Dense(len(train_counter.keys()), activation='softmax')(head_model)\n",
        "\n",
        "model = Model(inputs=conv_base.input, outputs=head_model)\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "  layer.trainable = False\n",
        "# vypis vrstev modelu\n",
        "#conv_base.summary()\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "batch_index = 0\n",
        "data_list = []\n",
        "while batch_index <= validation_imageflow.batch_index:\n",
        "  data = validation_imageflow.next()\n",
        "  data_list.append(data[0])\n",
        "  batch_index += 1\n",
        "\n",
        "# now, data_array is the numeric data of whole images\n",
        "#x_data = []\n",
        "#y_data = []\n",
        "#while True:\n",
        "#  try:\n",
        "#    n = next(validation_imageflow)\n",
        "#    print(f'({n[0]}, {n[1]})')\n",
        "#    x_data.append(n[0])\n",
        "#    y_data.append(n[1])\n",
        "#  except StopIteration:\n",
        "#    print('last item reached')\n",
        "#    break\n",
        "\n",
        "#accuracy_callback = AccuracyCallback((x_data, y_data), train_counter.keys())\n",
        "#class_weight = {0: 10, 1: 1.0, 2: 100.0}\n",
        "class_weight = {0: 1.0, 1: 1.0, 2: 1.0}\n",
        "\n",
        "print('head_model training started')\n",
        "history = model.fit(\n",
        "    x=train_imageflow,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_imageflow,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weight\n",
        "    )\n",
        "\n",
        "train_imageflow.reset()\n",
        "validation_imageflow.reset()\n",
        "\n",
        "for layer in conv_base.layers[-4:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "  print(f'{layer} is trainable = {layer.trainable}')\n",
        "\n",
        "print('Model recompilation')\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print('unfreezed model training started')\n",
        "history = model.fit(\n",
        "    x=train_imageflow,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_imageflow,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weight\n",
        "    )\n",
        "\n",
        "# 5. vypis vysledku a vizualizace\n",
        "\n",
        "#print(classification_report(val_features, val_labels))\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "xepochs = range(1, len(accuracy)+1)\n",
        "\n",
        "plt.plot(xepochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(xepochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(xepochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(xepochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.figure()\n",
        "\n",
        "df = pd.DataFrame(history.history)\n",
        "print(df)\n",
        "\n",
        "#for data, label in validation_imageflow:\n",
        "#  print('data batch shape:', data.shape)\n",
        "#  plt.imshow(data[0])\n",
        "#  plt.title(str(label[0]))\n",
        "#  print('label batch shape:', label.shape)\n",
        "#  break\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXuRVqzuco_m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}